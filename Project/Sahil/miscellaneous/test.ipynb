{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c12f48b2724405aa59055b6f4d0ba4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    cache_dir=\"/data5/home/sahilm/NLP_Project/Llama_2_7b_chat_hf\"\n",
    "    ).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", \n",
    "                                          cache_dir=\"/data5/home/sahilm/NLP_Project/Llama_2_7b_chat_hf\"\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    torch_dtype = torch.float16,\n",
    "    device = 0 if device.type == \"cuda\" else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hii How are you? Let's play cricket\"\n",
    "\n",
    "template = f\"\"\"Translate the following text to Hindi:\\nText: {text}\\nOutput: \"\"\"    \n",
    "\n",
    "prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "Your task is to translate given text into other language specified by user\n",
    "<</SYS>>\n",
    "\n",
    "{template} [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Translate the following text to Hindi:\n",
      "Text: Hii How are you? Let's play cricket\n",
      "Output: हिई कैसे हैं आप? क्रिकेट खेलो\n",
      "\n",
      "Please provide the text you want to translate and I will be happy to help you.\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    template,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Result: Translate the following text to Hindi:\n",
      "Text: Hii How are you? Let's play cricket\n",
      "Output: हिई कैसे हैं आप? क्रिकेट खेलो\n",
      "\n",
      "Please provide the text you want to translate and I will be happy to help you.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for seq in sequences:\n",
    "    cnt+=1\n",
    "    print(cnt)\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "जीससस के समककाले में, जेसस ने अपने द्वारा प्रार्थना की थी कि देश्य के सदस्यों के लिए.\n",
      "कारण के साथ समाप्ति तक चलना चाहिए क्योंकि ईश्वर की जागhat से हमारे सामने अधिक जागhat है |\n",
      "क्यों सच में लव के साथ अन्य से सेक्सुअल अपराध से इस्तेमाल नहीं करता?\n",
      "कठोर स्पोर्ट्सवार का निर्माता उधारने की मात्रा से अधिक स्पोर्ट्सवार का माτ्रा उधारने के लिए अधिक स्पोर्ट्सवार का मात्रा उधारने के लिए कठोर स्पोर्ट्सवार का न\n",
      "हमारा प्राकृतिक विज्ञान हमें क्या करेगा?\n",
      "जाकob के निर्वाण से सभी थे 70 व्यक्ति.\n",
      "क्रिपा के साथ भगवान का प्रेरणा प्राप्त होना चाहिए\n",
      "वह उसे सीढ़ियाँ सुझाव में सुझाव दे रहा है\n",
      "यदि आप अपने घर के खाते बाहर सफेद समुदाय में डालते हैं, तो वह लाल हो जायेंगे\n",
      "क्या हमें दूसरों की सुख की सुझाव देना चाहिये\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Open both files\n",
    "with open(\"/data5/home/sahilm/NLP_Project/Dataset/IndicNECorp1.0/English-Mizo/parallel/en-lus-test-en.txt\", \"r\") as file1, open(\"/data5/home/sahilm/NLP_Project/Dataset/IndicNECorp1.0/English-Mizo/parallel/en-lus-test-lus.txt\", \"r\") as file2:\n",
    "    # Iterate over lines from both files simultaneously\n",
    "    cnt = 0\n",
    "    for line1, line2 in zip(file1, file2):\n",
    "        cnt+=1\n",
    "        # Process the lines (e.g., print them)\n",
    "        # print(\"Line from file1:\", line1.strip())\n",
    "        # print(\"Line from file2:\", line2.strip())\n",
    "        # text = line1.strip()[:20]\n",
    "        text = line1.strip()\n",
    "        template = f\"\"\"Translate the following text to Hindi:\\nText: {text}\\nOutput: \"\"\"  \n",
    "\n",
    "        sequences = pipeline(\n",
    "            template,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_length=200,\n",
    "        )\n",
    "        output = sequences[0]['generated_text']\n",
    "        \n",
    "        sentences_after_output = re.findall(r'Output:(.*)', output)\n",
    "        print(sentences_after_output[0].strip())\n",
    "\n",
    "        if cnt==10:\n",
    "            break\n",
    "        # print(find_sentence_between_last_triple_backticks(output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bleu_score(file_path):\n",
    "    bleu_scores = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"BLEU Score:\" in line and \"Average\" not in line:\n",
    "                try:\n",
    "                    bleu_score = float(line.split(\"BLEU Score:\")[1].strip())\n",
    "                    bleu_scores.append(bleu_score)\n",
    "                except ValueError:\n",
    "                    # If there's an issue converting to float, skip this line\n",
    "                    continue\n",
    "    return bleu_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Scores: [0.02601300475114445, 0.01332691735545882, 0.05094110796339642, 0.0, 0.015153804040598334, 0.015240512444593133, 0.00728875805926182, 0.0, 0.010118063481312316, 0.023980296761827107, 0.07037324209679535, 0.04179252131328987, 0.01310368481704471, 0.019949282861652862, 0.040824829046386304, 0.030261051572977482, 0.02777619034011792, 0.018690183721524995, 0.06541868941754436, 0.024218026052883736, 0.039281465090051315, 0.01362503208749583, 0.010567253445701707, 0.010802314890908065, 0.05231223689135342, 0.019933673568014454, 0.02145851237135921, 0.009849349468888718, 0.0012328030158643326, 0.0169861974906263, 0.044939163285563015, 0.20556680845025987, 0.018850319022747353, 0.0, 0.01635904350868638, 0.1778279410038923, 0.00786168996992071, 0.0, 0.008517399705356638, 0.03358244811689829, 0.005751876324997854, 0.015318500535118459, 0.09554427922043669, 0.023980296761827107, 0.1769859637293783, 0.05372849659117709, 0.06500593260343691, 0.0, 0.11868405219520975, 0.04038503063059995, 0.05373277909396075, 0.03392268780792677, 0.04939382737115371, 0.03994198862354488, 0.030934588294313718, 0.01284618972676772, 0.033031643180138064, 0.034052233956373766, 0.0, 0.047077806821680744, 0.025671829680885088, 0.01935526899434156, 0.0, 0.019566761078768414, 0.04913270548144422, 0.02062457446156057, 0.011328360454400999, 0.038016654758067044, 0.028006570816358187, 0.006510688093168524, 0.019049156651279906, 0.022702294218557836, 0.012527569750499231, 0.003279163301859273, 0.015936357366603364, 0.008531104334876973, 0.04469394132307655, 0.03303164318013808, 0.16990442448471224, 0.025124218547395095, 0.07164684238257436, 0.5081327481546147, 0.012034130950069917, 0.03948864231460671, 0.018693000799960027, 0.0342347495586902, 0.04269823452354303, 0.04841524713034601, 0.02777619034011792, 0.014126508859988748, 0.013217947626377298, 0.0, 0.0, 0.0, 0.09058752341587764, 0.013679192123121896, 0.008648024585901885, 0.05307712171072445, 0.014317499041762431, 0.026095171736158027, 0.012204811114796843, 0.019900763312868126, 0.012109013026441871, 0.04073667958734362, 0.008683728271751297, 0.033031643180138064, 0.05501080739920602, 0.018850319022747353, 0.048034600402898434, 0.0, 0.014203609079723397, 0.021972813874997166, 0.009091091175882193, 0.009897037622951592, 0.018440431524622675, 0.01706602014357155, 0.0446323613785333, 0.008388487457231183, 0.03960111677234158, 0.020255986027125642, 0.013679192123121896, 0.012817749512462208, 0.02203823930718979, 0.0, 0.032671237560503906, 0.01837177448896075, 0.1683910986612003, 0.03104578053097407, 0.016824108947695062, 0.11362193664674995, 0.0, 0.005515757588967432, 0.16990442448471224, 0.008282282660969604, 0.01706602014357155, 0.009424388965893711, 0.039281465090051315, 0.02729967835246154, 0.039281465090051315, 0.019434963546171094, 0.015179921662582774, 0.01618861356572822, 0.06257106818159155, 0.0012042941150643186, 0.03155984539112946, 0.025518615589394285, 0.02310128340501537, 0.03226013518927287, 0.022111541438690575, 0.009410489957951634, 0.0, 0.10600313379512592, 0.012285946074705657, 0.02777619034011792, 0.02062457446156057, 0.12278260149096115, 0.027007097700389556, 0.052381754867968186, 0.009498525867740094, 0.017395797375642234, 0.03342866121562732, 0.023980296761827107, 0.0063161840849674045, 0.01577545640301219, 0.23879190165893138, 0.018817197551587818, 0.001653752159663036, 0.17337056134697476, 0.0, 0.03303164318013808, 0.010511846841633778, 0.13401910076814988, 0.0, 0.030064545690526145, 0.0, 0.025271148634948993, 0.03455747170954952, 0.029424728455584886, 0.18894448043123793, 0.05231223689135342, 0.013217947626377298, 0.025405213326725105, 0.01582331396625117, 0.18713114109010565, 0.06846046760764757, 0.02043370997308395, 0.040824829046386304, 0.020034704329441457, 0.029051817443414188, 0.0051459869478619165, 0.024415057111239653, 0.04411629359322707, 0.12382811752342573, 0.015815216252224023, 0.03611948985310407, 0.11824203898147173, 0.031091006235412864, 0.08208917858553258, 0.036362270465000714, 0.026997729811594123, 0.029556479778261396, 0.020345970436499224, 0.07978199887317745, 0.0, 0.028556529017323657, 0.039073802494525016, 0.050712153369465586, 0.0, 0.030452555559828284, 0.015603043420373072, 0.025098621243978974, 0.05307712171072445, 0.03868526789974356, 0.028517539529041507, 0.25608891792067445, 0.05372849659117709, 0.06257106818159155, 0.06164542728425844, 0.01801210737536247, 0.021105340631872645, 0.0, 0.040824829046386304, 0.00555087508173553, 0.023980296761827107, 0.024925978674400287, 0.028634401465295497, 0.023480087201163912, 0.04167227247694064, 0.020876149875884896, 0.00043012178799575296, 0.021400047286221472, 0.05437427682227521, 0.023446342673728394, 0.007039372171487214, 0.06164542728425844, 0.0, 0.023980296761827107, 0.009031565546286669, 0.019090277826420414, 0.008071364532479952, 0.058609033660640374, 0.02984745896009824, 0.008301095462822575, 0.0, 0.02777619034011792, 0.0221625475730487, 0.00956240657444202, 0.0, 0.017502413882486995, 0.10305224267080783, 0.016273889955107996, 0.01553712569276035, 0.010275474580767148, 0.022393028921480054, 0.0423682412589593, 0.019900763312868126, 0.0, 0.039791617478097244, 0.010859480700217564, 0.030934588294313718, 0.009812163258584559, 0.008283969733745658, 0.02560744480557418, 0.0136352834976593, 0.01387195318363841, 0.05094110796339642, 0.02777619034011792, 0.009498525867740094, 0.11302127100918531, 0.009163801705346999, 0.010043468297595231, 0.03986357128268015, 0.01859351593152887, 0.0864638926009796, 0.019900763312868126, 0.1495348781221221, 0.007087648989046159, 0.09329460218997072, 0.02925226826055808, 0.022710171642664416, 0.0, 0.04465541607614766, 0.0, 0.06500593260343691, 0.009876041910810221, 0.0, 0.024088562704853513, 0.045131921809482646, 0.0808764862779457, 0.0239652533986352, 0.006446672494240213, 0.0605543865104477, 0.053871541262825985, 0.010862721615727716, 0.1137168193487524, 0.009152541620698935, 0.010864991539917157, 0.0, 0.029214727989184803, 0.0, 0.06030725360407769, 0.012410963317921997, 0.0, 0.01340082578177889, 0.0, 0.01893405895135384, 0.024822529802838878, 0.012085511779959531, 0.0, 0.03226013518927287, 0.027196801514995272, 0.033241378434410024, 0.010329222874429908, 0.013021282907502303, 0.007316627729209994, 0.03798229226827674, 0.0, 0.41113361690051975, 0.02043370997308395, 0.017152164326621384, 0.011502783619900045, 0.03199185823258922, 0.0, 0.04574636154673318, 0.006203611270809164, 0.018887059924361526, 0.04411629359322707, 0.039447492477737316, 0.0, 0.01626739260030573, 0.017033186037639283, 0.023980296761827107, 0.04988046850531109, 0.012388559502462976, 0.0044898990925144695, 0.03226013518927287, 0.13383371848099188, 0.011451997463067555, 0.02297185935845028, 0.03722520852859804, 0.0, 0.010182425646195498, 0.024289783953423513, 0.023143514978409278, 0.022565401296922416, 0.03550467708240432, 0.022416933501922302, 0.014886459693587576, 0.0, 0.007963152237939303, 0.004893122307177828, 0.007108486297836999, 0.0169861974906263, 0.011833064662823948, 0.011689761696528609, 0.0695362172133984, 0.07356556000975763, 0.05880962777751932, 0.017239238102071234, 0.0, 0.014296145628396562, 0.016789125215525624, 0.11362193664674995, 0.02777619034011792, 0.012689457668763376, 0.028517539529041507, 0.05538696232597745, 0.012163737473833695, 0.06505218374091319, 0.024512401940754224, 0.16348126556655487, 0.08461633959345022, 0.011657633846595293, 0.03449612988879278, 0.024761510494160165, 0.022416933501922302, 0.05685765640252835, 0.039281465090051315, 0.010331208012220438, 0.010182425646195498, 0.03455747170954952, 0.009313150330122724, 0.18951629567590741, 0.03219290164685344, 0.0169861974906263, 0.03902903778912444, 0.01606243474117787, 0.42818185319516083, 0.022416933501922302, 0.00818849820927114, 0.02560744480557418, 0.0439891724758422, 0.010262678347502956, 0.05372849659117709, 0.013618796864073041, 0.025474063272944283, 0.02560744480557418, 0.01618861356572822, 0.06560264840246194, 0.040824829046386304, 0.01414733290395472, 0.01525533981505719, 0.014143371354519225, 0.015492483943164657, 0.050990202976183285, 0.0428361950754725, 0.02248078193461733, 0.019457849455649996, 0.04328649145305472, 0.0, 0.06389431042462725, 0.0, 0.014449575139835526, 0.030185197980400025, 0.009872120496476587, 0.10294994188297393, 0.0, 0.03530717633542467, 0.013217947626377298, 0.05231223689135342, 0.033241378434410024, 0.01794073254089892, 0.01874585289964774, 0.047422195449693935, 0.048549177170732344, 0.0010999588949849289, 0.009472995278817151, 0.013217947626377298, 0.012384901282810543, 0.04537922867531812, 0.03772657799190421]\n",
      "431\n",
      "15.349876538801125\n",
      "0.035614562735037415\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/data5/home/sahilm/NLP_Project/zero_shot_Hindi_output.txt\"\n",
    "scores = extract_bleu_score(file_path)\n",
    "print(\"BLEU Scores:\", scores)\n",
    "print(len(scores))\n",
    "print(sum(scores))\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5081327481546147\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    if scores[i]>0.5:\n",
    "        print(scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def calculate_bleu_score(reference, candidate):\n",
    "    # Tokenize reference and candidate strings\n",
    "    reference_tokens = word_tokenize(reference.lower())\n",
    "    candidate_tokens = word_tokenize(candidate.lower())\n",
    "    print(reference_tokens)\n",
    "    # print([reference_tokens])\n",
    "    print(candidate_tokens)\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens,weights=(1,0,0,0),smoothing_function=SmoothingFunction().method1)\n",
    "    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'i', 'am', 'sahil']\n",
      "['hi', 'i', 'the', 'sahil']\n",
      "0.1880301546543197\n"
     ]
    }
   ],
   "source": [
    "ref = \"Hi I am Sahil\"\n",
    "txt = \"Hi I the Sahil\"\n",
    "\n",
    "print(calculate_bleu_score(ref,txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 1-gram: 0.750000\n",
      "Individual 2-gram: 0.333333\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data5/home/sahilm/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/data5/home/sahilm/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# n-gram individual BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'tgh', 'test']\n",
    "print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
    "print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
    "print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
    "print('Individual 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Hindi_and_Output_score(file_path):\n",
    "    hindi = []\n",
    "    out = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"HINDI: \" in line:\n",
    "                try:\n",
    "                    bleu_score = (line.split(\"HINDI: \")[1].strip())\n",
    "                    hindi.append(bleu_score)\n",
    "                except ValueError:\n",
    "                    # If there's an issue converting to float, skip this line\n",
    "                    continue\n",
    "            if \"OUTPUT: \" in line:\n",
    "                try:\n",
    "                    bleu_score = (line.split(\"OUTPUT: \")[1].strip())\n",
    "                    out.append(bleu_score)\n",
    "                except ValueError:\n",
    "                    # If there's an issue converting to float, skip this line\n",
    "                    continue\n",
    "    return hindi,out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/data5/home/sahilm/NLP_Project/zero_shot_Hindi_output.txt\"\n",
    "hindi,output = extract_Hindi_and_Output_score(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "431\n"
     ]
    }
   ],
   "source": [
    "print(len(hindi))\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = hindi[:len(hindi)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n",
      "431\n"
     ]
    }
   ],
   "source": [
    "print(len(hindi))\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['जिसके जवाब में पाक ने अच्छी शुरुआत की थी.', 'यूरोपीय संघ के महत्वपूर्ण संस्थानों में यूरोपियन कमीशन, यूरोपीय संसद, यूरोपीय संघ परिषद, यूरोपीय न्यायलय एवं यूरोपियन सेंट्रल बैंक इत्यादि शामिल हैं।', 'कांग्रेस नेता तमिलनाडु से शिवगंगा लोकसभा क्षेत्र का प्रतिनिधित्व करते हैं.', 'संबंधन प्रयास के बारे में उपयोक्ता को प्रांप्ट करें', 'वित्त मंत्री ने घोषणा कि जमा बीमा और ऋण गारंटी निगम (डीआईसीजीसी) को जमा राशि बीमा का दायरा, जो इस समय 1 लाख रुपये है उसे बढ़ाकर प्रति जमाकर्ता 5 लाख रुपये करने की अनुमति प्रदान कर दी गई है।']\n"
     ]
    }
   ],
   "source": [
    "print(hindi[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['पाकिस्तान ने स्थापना की.', 'एरोपेन यूनियन ने सात महत्वाकांक निर्देशक शासन के साथ अधिकार का आधार बनाया है: ईरपेल पार्लीमेंट, ईरोपेन कॉउन्सिल, कॉउन्सिल ऑफ ईरोपेन यूनियन, ईरोपेन कमीशन, कोर्ट ऑफ जस्टिसी ऑफ ईरोपेन यूनियन, ईरोपेन', 'कांग्रेस नेता सिवागंगा लोक सभा सेгमेंट के लिए तमिलनाडु से खड़ा है।', 'जunction उपलब्धि की सुझाव दें', 'देखा है, मंत्री ने कहा कि डेपोजिट इंसरेंसी और कредит गारंतनी कॉर्पोरेशन (DICGC) को उठाना है डेपोजिट इंसरेंसी कोरोखा के साथ और क्रेडिट गारंतनी क्रमांक को बढावा देना.']\n"
     ]
    }
   ],
   "source": [
    "print(output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def calculate_bleu_score(reference, candidate):\n",
    "    # Tokenize reference and candidate strings\n",
    "    reference_tokens = word_tokenize(reference.lower())\n",
    "    candidate_tokens = word_tokenize(candidate.lower())\n",
    "    # print(reference_tokens)\n",
    "    # print([reference_tokens])\n",
    "    # print(candidate_tokens)\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens,weights=(1/4,1/4,1/4,1/4),smoothing_function=SmoothingFunction().method1)\n",
    "    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035614562735037415\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "for i in range(len(output)):\n",
    "    total_score += calculate_bleu_score(hindi[i],output[i])\n",
    "\n",
    "print(total_score/len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
