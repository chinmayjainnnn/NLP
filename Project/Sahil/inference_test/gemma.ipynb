{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/raid/home/chinmayjain/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pip install accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.40s/it]\n"
     ]
    }
   ],
   "source": [
    "access_token =\"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\",cache_dir=\"/raid/home/chinmayjain/Sahil/NLP_Project/gemma/model\",token = access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b-it\",cache_dir=\"/raid/home/chinmayjain/Sahil/NLP_Project/gemma/model\", device_map=\"auto\",token = access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = \"All 176 passengers died in the incident.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following text from English to Hindi: All 176 passengers died in the incident. The plane crashed into a mountainside, and the wreckage spread over a wide area. The impact caused a fire, which consumed the entire plane. The cause of the crash is still under investigation.\n",
      "\n",
      "**Hindi translation:**\n",
      "\n",
      "सincident में सभी 176 यात्रों की मृत्यु हो गई थी। विमान पर्वत की एक तरफ गिरा और रिक्ते का बड़ा क्षेत्र में फैल गया था। प्रभाव एक आग भी उत्पन्न हुआ था जो पूरे विमान को जला दे गया था। दुर्घट के कारण अभी भी जांच हो रही है।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the following text from English to Hindi: {english}\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><INST> Translate following text from English to Hindi: All 176 passengers died in the incident. </INST>\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "All 176 passengers perished in the incident.\n",
      "\n",
      "**Translation:**\n",
      "\n",
      "सincident में सभी 176 यात्रों की मृत्यु हो गई।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"<s><INST> Translate following text from English to Hindi: {english} </INST>\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate from English to Hindi no extra text\n",
      "[English]: All 176 passengers died in the incident.\n",
      "[Hindi]: सभी 176 यात्रों की मृत्यु इस घटना में हुई थी।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate from English to Hindi no extra text\n",
    "[English]: {english}\n",
    "[Hindi]:\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a Translator from English to Hindi:\n",
      "\n",
      "User: What is the Translation of the sentence given below. \n",
      "[English]: All 176 passengers died in the incident.\n",
      "[Hindi]: (Translation)\n",
      "\n",
      "Please provide the translation of the sentence in Hindi.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "The translation of the sentence in Hindi is:\n",
      "\n",
      "**All 176 passengers perished in the incident.**\n",
      "\n",
      "**Translation:**\n",
      "\n",
      "모든 176 यात्रे इस घटना में मृत्यु हो गए।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"System: You are a Translator from English to Hindi:\n",
    "\n",
    "User: What is the Translation of the sentence given below. \n",
    "[English]: {english}\n",
    "[Hindi]:\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
