{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  5.31s/it]\n"
     ]
    }
   ],
   "source": [
    "access_token =\"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sarvamai/OpenHathi-7B-Hi-v0.1-Base\",cache_dir=\"/raid/home/chinmayjain/Sahil/NLP_Project/open_hathi/model\",token = access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sarvamai/OpenHathi-7B-Hi-v0.1-Base\",cache_dir=\"/raid/home/chinmayjain/Sahil/NLP_Project/open_hathi/model\", device_map=\"auto\",token = access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = \"All 176 passengers died in the incident.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following text from English to Hindi: All 176 passengers died in the incident.\n",
      "\n",
      "इसका क्या मतलब है?\n",
      "---\n",
      "The incident refers to a tragic airplane accident that occurred on November 29, 1996, in the city of Guangzhou, China. यह घटना एक बोइंग 747-400 यात्री विमान के दुर्घटनाग्रस्त होने के कारण हुई, जिसमें सवार सभी 176 यात्रियों और चालक दल के सदस्यों की मौत हो गई। The cause of the crash was attributed to a combination of factors, including pilot error, mechanical failure, and poor weather conditions.\n",
      "\n",
      "दुर्घटना के बाद, दुर्घटना की जांच की गई और कई निष्कर्ष निकाले गए। The National Transportation Safety Board of China determined that the crash was caused by a combination of factors, including pilot error, mechanical failure, and poor weather conditions. पायलट ने विमान को बहुत अधिक ऊंचाई पर उड़ाया, जिससे यह नियंत्रण से बाहर हो गया और जमीन से टकरा गया। The mechanical failure was attributed to a faulty pitot-static system, which provided inaccurate data to the pilots, leading to their misinterpretation of the aircraft's position and altitude. खराब मौसम की स्थिति, जिसमें कम दृश्यता और तेज हवाएं शामिल थीं, ने भी पायलटों के लिए स्थिति को समझना और प्रतिक्रिया देना मुश्किल बना दिया।\n",
      "\n",
      "The crash of the Boeing 747-400 passenger plane in Guangzhou, China, on November 29, 1996, was a tragic event that claimed the lives of all 176 passengers and crew members on board. यह घटना पायलट त्रुटि, यांत्रिक विफलता और खराब मौसम की स्थिति सहित कई कारकों के संयोजन के कारण हुई थी। The crash investigation revealed that the pilots had misinterpreted the aircraft's position and altitude, leading to the plane's descent and subsequent crash into the ground. इस घटना ने विमानन सुरक्षा और विमान रखरखाव की सुरक्षा के महत्व पर प्रकाश डाला, और इसने विमानन उद्योग में सुरक्षा उपायों और प्रक्रियाओं में सुधार के लिए एक उत्प्रेरक के रूप में काम किया।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the following text from English to Hindi: {english}\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<INST> Translate following text from English to Hindi: All 176 passengers died in the incident. </INST>\n",
      "\n",
      "<प्रश्न> क्या हम इस परिकल्पना का निष्कर्ष निकाल सकते हैं कि \"सभी 176 यात्रियों की मृत्यु हो गई\"?\n",
      "---\n",
      "Step 1: Analyze the given information\n",
      "प्रदान की गई जानकारी में कहा गया है कि 176 यात्रियों की मृत्यु हो गई।\n",
      "\n",
      "Step 2: Identify the hypothesis\n",
      "परिकल्पना यह है कि \"सभी 176 यात्रियों की मृत्यु हो गई\"।\n",
      "\n",
      "Step 3: Compare the information with the hypothesis\n",
      "प्रदान की गई जानकारी में कहा गया है कि 176 यात्रियों की मृत्यु हो गई, जो परिकल्पना के कथन के साथ मेल खाती है।\n",
      "\n",
      "Step 4: Conclusion\n",
      "प्रदान की गई जानकारी के आधार पर, हम यह निष्कर्ष निकाल सकते हैं कि \"सभी 176 यात्रियों की मृत्यु हो गई\"।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"<s><INST> Translate following text from English to Hindi: {english} </INST>\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate from English to Hindi no extra text\n",
      "[English]: All 176 passengers died in the incident.\n",
      "[Hindi]: इस घटना में सभी 176 यात्रियों की मौत हो गई।\n",
      "\n",
      "Step 2: Identify the subject of the sentence.\n",
      "इस मामले में, विषय \"सभी 176 यात्री\" है।\n",
      "\n",
      "Step 3: Determine the tense of the sentence.\n",
      "इस मामले में, वाक्य वर्तमान काल में है।\n",
      "\n",
      "Step 4: Determine the verb form.\n",
      "इस मामले में, क्रिया रूप \"मृत\" है।\n",
      "\n",
      "Step 5: Determine the object of the sentence.\n",
      "इस मामले में, वस्तु \"यात्री\" है।\n",
      "\n",
      "Step 6: Form the sentence.\n",
      "अंग्रेजी से हिंदी में अनुवाद करते समय, हम \"सभी\" को \"सभी\" से बदलते हैं, \"176\" को \"176\" से बदलते हैं, और \"यात्री\" को \"यात्री\" से बदलते हैं।\n",
      "\n",
      "Step 7: Check the sentence for correctness.\n",
      "अंग्रेजी से हिंदी में अनुवाद करते समय, हम यह सुनिश्चित करते हैं कि वाक्य व्याकरणिक रूप से सही है और इसमें कोई त्रुटि नहीं है।\n",
      "\n",
      "Step 8: Confirm the translation.\n",
      "अंग्रेजी से हिंदी में अनुवाद करते समय, हम यह सुनिश्चित करते हैं कि अनुवाद सटीक और सही है।\n",
      "\n",
      "Step 9: Provide the translated sentence.\n",
      "अंग्रेजी से हिंदी में अनुवाद करते समय, हम \"सभी 176 यात्री इस घटना में मारे गए\" वाक्य का अनुवाद करते हैं।\n",
      "\n",
      "Step 10: Provide the justification for the translation.\n",
      "अंग्रेजी से हिंदी में अनुवाद करते समय, हम यह सुनिश्चित करते हैं कि अनुवाद व्याकरणिक रूप से सही है और इसमें कोई त्रुटि नहीं है।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate from English to Hindi no extra text\n",
    "[English]: {english}\n",
    "[Hindi]:\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a Translator from English to Hindi:\n",
      "\n",
      "User: What is the Translation of the sentence given below. \n",
      "[English]: All 176 passengers died in the incident.\n",
      "[Hindi]: 176 यात्रियों की इस दुर्घटना में मौत हो गई।\n",
      "\n",
      "The answer is:\n",
      "---\n",
      "[हिंदी]: 176 यात्रियों की इस दुर्घटना में मौत हो गई।\n",
      "\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"System: You are a Translator from English to Hindi:\n",
    "\n",
    "User: What is the Translation of the sentence given below. \n",
    "[English]: {english}\n",
    "[Hindi]:\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids,max_length=2048,top_k=5,temperature=0.1,do_sample=True)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
    "print(tokenizer.decode(outputs[0],skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "print(\"\\n=============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
